{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "375572cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/milad/.local/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.12.4)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: packaging in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/milad/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/milad/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/milad/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/milad/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/milad/.local/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/milad/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/milad/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/milad/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/milad/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/milad/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /home/milad/.local/lib/python3.10/site-packages (2.9.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/milad/.local/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/milad/.local/lib/python3.10/site-packages (from pandas) (1.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/milad/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/milad/.local/lib/python3.10/site-packages (3.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from nltk) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: hazm in /home/milad/.local/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: nltk==3.3 in /home/milad/.local/lib/python3.10/site-packages (from hazm) (3.3)\n",
      "Requirement already satisfied: libwapiti>=0.2.1 in /home/milad/.local/lib/python3.10/site-packages (from hazm) (0.2.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from nltk==3.3->hazm) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.4 MB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/milad/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/milad/.local/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.23.1)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=cc7ee3283f39c6fd13917ec57450919c20883f004cde54e68d54709e357b102f\n",
      "  Stored in directory: /home/milad/.cache/pip/wheels/9b/13/01/6f3a7fd641f90e1f6c8c7cded057f3394f451f340371c68f3d\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sklearn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed scikit-learn-1.1.1 scipy-1.8.1 sklearn-0.0 threadpoolctl-3.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install hazm\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5aad9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hazm import *\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e69ab9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/milad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f22fde4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '!']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hello, world!\"\n",
    "print (nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9a89b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DID      Date    Cat                                               Text\n",
      "0     1S1  75\\04\\02  adabh  جاودانگي در زندگي گروهي از طريق هنر \\nنگاهي به...\n",
      "1  DID2S1  75\\04\\02  adabh  رويدادهاي هنري جهان \\nنمايشگاه هنر در خدمت ديك...\n",
      "2  DID3S1  75\\04\\02  adabh  برديوار نگارخانه ها \\nگالري گلستان: \\nنمايشگاه...\n",
      "3  DID4S1  75\\04\\02  ejtem  بازي را جدي بگيريم \\nمطالعه اي مقدماتي پيرامون...\n",
      "4  DID5S1  75\\04\\02  elmfa  تخته سياه و غباري كه سترده نمي شود... \\nاشاره;...\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"hamshahri.csv\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f14b8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 165233 rows.\n"
     ]
    }
   ],
   "source": [
    "data_len = dataset.shape[0]\n",
    "print('Dataset has {} rows.'.format(data_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e245ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category \". راسته: . شب كلاه شكلان (Semaeostomae)\" contains 1 posts.\n",
      "Category \"Adabh\" contains 13 posts.\n",
      "Category \"Aeqts\" contains 10 posts.\n",
      "Category \"Akhar\" contains 10 posts.\n",
      "Category \"Busiw\" contains 9 posts.\n",
      "Category \"Cinew\" contains 3 posts.\n",
      "Category \"Cultw\" contains 651 posts.\n",
      "Category \"Econo\" contains 6 posts.\n",
      "Category \"Eqtes\" contains 14 posts.\n",
      "Category \"Globa\" contains 4 posts.\n",
      "Category \"Gozar\" contains 3 posts.\n",
      "Category \"Kharj\" contains 22 posts.\n",
      "Category \"Lifew\" contains 3 posts.\n",
      "Category \"Musical\" contains 3 posts.\n",
      "Category \"Newsp\" contains 9 posts.\n",
      "Category \"Nnaft\" contains 6 posts.\n",
      "Category \"Polig\" contains 2 posts.\n",
      "Category \"Santj\" contains 4 posts.\n",
      "Category \"Sciew\" contains 6 posts.\n",
      "Category \"Shari\" contains 8 posts.\n",
      "Category \"Siasi\" contains 18 posts.\n",
      "Category \"Sporw\" contains 50 posts.\n",
      "Category \"Theatre\" contains 3 posts.\n",
      "Category \"Thought\" contains 2 posts.\n",
      "Category \"abksh\" contains 495 posts.\n",
      "Category \"adabh\" contains 5171 posts.\n",
      "Category \"adarman\" contains 31 posts.\n",
      "Category \"aeqts\" contains 1378 posts.\n",
      "Category \"akhar\" contains 13811 posts.\n",
      "Category \"art\" contains 113 posts.\n",
      "Category \"artw\" contains 984 posts.\n",
      "Category \"axrooz\" contains 454 posts.\n",
      "Category \"bankb\" contains 765 posts.\n",
      "Category \"bazar\" contains 282 posts.\n",
      "Category \"books\" contains 229 posts.\n",
      "Category \"busiw\" contains 56 posts.\n",
      "Category \"cartoon\" contains 164 posts.\n",
      "Category \"cinama\" contains 52 posts.\n",
      "Category \"cinew\" contains 123 posts.\n",
      "Category \"city\" contains 191 posts.\n",
      "Category \"cultw\" contains 346 posts.\n",
      "Category \"donya\" contains 28 posts.\n",
      "Category \"earth\" contains 190 posts.\n",
      "Category \"econo\" contains 330 posts.\n",
      "Category \"econw\" contains 1030 posts.\n",
      "Category \"ejtem\" contains 8320 posts.\n",
      "Category \"elmfa\" contains 1785 posts.\n",
      "Category \"elmif\" contains 8888 posts.\n",
      "Category \"eqtes\" contains 16661 posts.\n",
      "Category \"eqtsj\" contains 329 posts.\n",
      "Category \"ertebat\" contains 9 posts.\n",
      "Category \"erteg\" contains 19 posts.\n",
      "Category \"gards\" contains 374 posts.\n",
      "Category \"globa\" contains 176 posts.\n",
      "Category \"gofgu\" contains 11 posts.\n",
      "Category \"goftg\" contains 5 posts.\n",
      "Category \"gozar\" contains 1421 posts.\n",
      "Category \"gqarn\" contains 8 posts.\n",
      "Category \"gungn\" contains 7555 posts.\n",
      "Category \"hamln\" contains 93 posts.\n",
      "Category \"havad\" contains 3758 posts.\n",
      "Category \"igozar\" contains 3 posts.\n",
      "Category \"ikabar\" contains 80 posts.\n",
      "Category \"imaqal\" contains 12 posts.\n",
      "Category \"infor\" contains 171 posts.\n",
      "Category \"intep\" contains 797 posts.\n",
      "Category \"jjahn\" contains 220 posts.\n",
      "Category \"jvarz\" contains 1179 posts.\n",
      "Category \"kharj\" contains 14666 posts.\n",
      "Category \"lastp\" contains 233 posts.\n",
      "Category \"lifew\" contains 492 posts.\n",
      "Category \"lite\" contains 30 posts.\n",
      "Category \"maqal\" contains 1439 posts.\n",
      "Category \"maref\" contains 571 posts.\n",
      "Category \"media\" contains 37 posts.\n",
      "Category \"mohit\" contains 954 posts.\n",
      "Category \"mskan\" contains 66 posts.\n",
      "Category \"musical\" contains 108 posts.\n",
      "Category \"nameh\" contains 762 posts.\n",
      "Category \"newsp\" contains 457 posts.\n",
      "Category \"nnaft\" contains 1226 posts.\n",
      "Category \"norooz\" contains 9 posts.\n",
      "Category \"polig\" contains 1391 posts.\n",
      "Category \"sanat\" contains 350 posts.\n",
      "Category \"santj\" contains 615 posts.\n",
      "Category \"scien\" contains 155 posts.\n",
      "Category \"sciew\" contains 444 posts.\n",
      "Category \"shahr\" contains 8412 posts.\n",
      "Category \"shahz\" contains 99 posts.\n",
      "Category \"shari\" contains 10146 posts.\n",
      "Category \"shora\" contains 649 posts.\n",
      "Category \"shrst\" contains 8248 posts.\n",
      "Category \"siasi\" contains 17530 posts.\n",
      "Category \"socie\" contains 197 posts.\n",
      "Category \"soxan\" contains 1326 posts.\n",
      "Category \"sport\" contains 447 posts.\n",
      "Category \"sporw\" contains 955 posts.\n",
      "Category \"techn\" contains 217 posts.\n",
      "Category \"telfn\" contains 197 posts.\n",
      "Category \"theatre\" contains 28 posts.\n",
      "Category \"thought\" contains 150 posts.\n",
      "Category \"vrzsh\" contains 13011 posts.\n",
      "Category \"women\" contains 71 posts.\n",
      "Category \"ydsht\" contains 240 posts.\n",
      "Category \"youth\" contains 63 posts.\n",
      "Category \"zanan\" contains 278 posts.\n",
      "Category \"آرمينيابيلفلد آلمان باعث عكس العمل ها و واكنش هاي بسياري \" contains 1 posts.\n",
      "Category \"بزرگترين پل بتوني كشور به طول سه كيلومتر كه نقش عمده اي در كاهش بار \" contains 1 posts.\n",
      "Category \"به پرواز درآمد. شركت كنندگان از سي كشور بودند و چند نفري از آنان \" contains 1 posts.\n",
      "Category \"به گزارش خبرنگار همشهري در جلسه علني ديروز كه به رياست آقاي \" contains 1 posts.\n",
      "Category \"در حساسترين بازي اين هفته، يوونتوس، صدرنشين رقابتها در ورزشگاه \" contains 1 posts.\n",
      "Category \"رياضي دست يافت. به گزارش خبرنگار ما از باشگاه دانش پژوهان جوان، در \" contains 1 posts.\n",
      "Category \"شركت كرده بود در پايان اين رقابتها با كسب يك مدال طلا و يك برنز \" contains 1 posts.\n"
     ]
    }
   ],
   "source": [
    "cats = dataset[\"Cat\"]\n",
    "text = dataset[\"Text\"]\n",
    "unique_cats = np.unique(cats)\n",
    "cat_texts_count = dict.fromkeys(unique_cats, 0)\n",
    "\n",
    "for cat in cats:\n",
    "  cat_texts_count[cat] += 1\n",
    "\n",
    "for cat, cnt in cat_texts_count.items():\n",
    "  print('Category \"{}\" contains {} posts.'.format(cat, cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff1f3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"fa_stop_words.txt\", \"r\") as fa_stop_words:\n",
    "    stopwords = fa_stop_words.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78bd3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for faster result, we define the following lines of code outside the 'preprocessing' function\n",
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "stemmer = Stemmer()\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    text = re.sub('<[^<]+?>','', text)\n",
    "    text = ''.join(c for c in text if not c.isdigit())\n",
    "    text = ''.join(c for c in text if c not in punctuation)\n",
    "    text = normalizer.normalize(text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords) # remove stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a27854",
   "metadata": {},
   "source": [
    "## PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a5fe130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 155 unique tokens.\n",
      "Shape of data tensor: (165233, 250)\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(unique_cats)\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each post.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# The embedding dimension\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(dataset[\"Cat\"].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "# print(word_index)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(dataset[\"Cat\"].values)\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d9b6051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (165233, 113)\n",
      "(165233, 250) (165233, 113)\n",
      "(0, 250) (0, 113)\n"
     ]
    }
   ],
   "source": [
    "rows_of_train = 250000\n",
    "rows_of_test = 75000\n",
    "\n",
    "Y = pd.get_dummies(dataset['Cat']).values\n",
    "print('Shape of label tensor:', Y.shape)\n",
    "\n",
    "X_train = X[0:rows_of_train]\n",
    "X_test = X[rows_of_train: rows_of_train + rows_of_test]\n",
    "\n",
    "Y_train = Y[0:rows_of_train]\n",
    "Y_test = Y[rows_of_train:rows_of_train + rows_of_test]\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8cb0c3",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f30480ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_9 (Spatia  (None, 250, 100)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,081,006\n",
      "Trainable params: 5,081,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 113) and (None, 6) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m     11\u001b[0m tensorboard_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqvf5jbp9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/milad/.local/lib/python3.10/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 113) and (None, 6) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "history = model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbef095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
